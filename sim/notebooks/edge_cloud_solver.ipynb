{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from lib import wlanlrz_loader, rtt_matrix_loader, inference_loader\n",
    "from entities.solver_process import SolverProcess  \n",
    "from lib.common import disarrange\n",
    "import powerlaw\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import config.hyperparams as hp\n",
    "import datetime as dt\n",
    "from multiprocessing import Queue\n",
    "\n",
    "### WLAN-LRZ AP Data Loader ####\n",
    "desc = wlanlrz_loader.load_data_description(hp.AP_DESCR)\n",
    "data, coord_dataframe_list, total_ap, merged_raw_ap_data = wlanlrz_loader.load_data_parallel(hp.BUILDING, desc, mass_load=False)\n",
    "\n",
    "print(\"Total APs: {}\".format(total_ap))\n",
    "data['timestamp'] = data.index\n",
    "\n",
    "# Filter the dataser based on the minimum amount of users we want to serve\n",
    "data = data[data.total >= hp.minimum_agents_threshold]\n",
    "merged_raw_ap_data = merged_raw_ap_data.loc[merged_raw_ap_data.sum(axis=1) >= hp.minimum_agents_threshold]\n",
    "\n",
    "TOTAL_EPISODES = int(len(data))\n",
    "TIER_1_EN = int(round(total_ap))\n",
    "TIER_2_EN = int(round(total_ap/hp.T2_RATI0))\n",
    "TIER_3_EN = int(round(total_ap/hp.T3_RATI0))\n",
    "EN_RATIO = (TIER_1_EN, TIER_2_EN, TIER_3_EN)\n",
    "TOTAL_EN = int(TIER_1_EN + TIER_2_EN + TIER_3_EN)\n",
    "\n",
    "if hp.STORE_RESULTS:\n",
    "    try:\n",
    "        os.mkdir(hp.CSV_FOLDER)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % hp.CSV_FOLDER)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % hp.CSV_FOLDER)\n",
    "\n",
    "if hp.dataset_rtt:\n",
    "    ### LOAD LATENCY MATRIX FROM DATASET ###\n",
    "    print(\"Loading rtt matrix from dataset\")\n",
    "    clf = rtt_matrix_loader.analyze_data(source=hp.dataset_rtt, drange=1000, threshold=250, k=3)\n",
    "    rtt_matrix = rtt_matrix_loader.generate_data(clf, n=TIER_1_EN, m=TOTAL_EN)\n",
    "else:\n",
    "    # Prepare latency matrixes for all the EN classes with increasing latency based on distance from the edge \n",
    "    rtt_matrix_en_t1 = np.round(abs(np.random.normal(1, 0.2, (TIER_1_EN, TIER_1_EN))))\n",
    "    rtt_matrix_en_t2 = np.round(abs(np.random.normal(3, 1, (TIER_1_EN, TIER_2_EN))))\n",
    "    rtt_matrix_en_t3 = np.round(abs(np.random.normal(10, 1, (TIER_1_EN, TIER_3_EN))))\n",
    "\n",
    "    sns.distplot(rtt_matrix_en_t1.flatten(), hist=False, rug=True)\n",
    "    sns.distplot(rtt_matrix_en_t2.flatten(), hist=False, rug=True)\n",
    "    sns.distplot(rtt_matrix_en_t3.flatten(), hist=False, rug=True)\n",
    "\n",
    "    rtt_matrix = np.hstack([rtt_matrix_en_t1, rtt_matrix_en_t2, rtt_matrix_en_t3])\n",
    "\n",
    "np.random.shuffle(rtt_matrix)\n",
    "disarrange(rtt_matrix, axis=0)\n",
    "\n",
    "print(\"Plotting and saving RTT matrix\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "sns.heatmap(rtt_matrix, ax=ax)\n",
    "fig.tight_layout(w_pad=1.5)\n",
    "fig.savefig(\"../plots/rtt_matrix.pdf\")\n",
    "\n",
    "# Manually setting latency for colocated AP/EN\n",
    "for i in range(round(TIER_1_EN/hp.T1_RATIO)):\n",
    "    rtt_matrix[i][i] = 1\n",
    "            \n",
    "data[\"mean_task_latency\"] = np.nan\n",
    "data[\"mean_battery_usage\"] = np.nan\n",
    "data[\"convergence_time\"] = np.nan\n",
    "\n",
    "# Build queues for multithreading\n",
    "input_queue = Queue(maxsize=0)\n",
    "result_queue = Queue(maxsize=0)\n",
    "\n",
    "# Split original dataframes in n chunks\n",
    "processes = []\n",
    "data_t = np.array_split(data, hp.parallel_solvers)\n",
    "merged_raw_ap_data_t = np.array_split(merged_raw_ap_data, hp.parallel_solvers)\n",
    "\n",
    "print(\"Starting parallel solvers\")\n",
    "for d, mrad in zip(data_t, merged_raw_ap_data_t):\n",
    "    input_queue.put(d)\n",
    "    t = SolverProcess(\n",
    "        input_queue, result_queue, mrad,\n",
    "        len(d), TOTAL_EPISODES, EN_RATIO, rtt_matrix,\n",
    "        TIER_1_EN, TIER_2_EN, TIER_3_EN\n",
    "        )\n",
    "    processes.append(t)\n",
    "    t.start()\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Check if processes are alive (which forces a join() under the hood)\n",
    "# Extract data from the queue\n",
    "while 1:\n",
    "    running = any(p.is_alive() for p in processes)\n",
    "    while not result_queue.empty():\n",
    "        s = result_queue.get()\n",
    "        dfs.append(s)\n",
    "    if not running:\n",
    "        break\n",
    "\n",
    "data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "data.sort_index(inplace=True)\n",
    "data[\"datetime\"] = pd.to_datetime(data['timestamp'], unit='s')\n",
    "\n",
    "############# PLOTS: GROUP 1 #############\n",
    "\n",
    "fig, ax = plt.subplots(5, 1, figsize=(16, 16))\n",
    "\n",
    "### Plot showing the mean task execution time for each agent\n",
    "sns.lineplot(x=\"datetime\", y=\"mean_task_latency\", data=data, ax=ax[0], dashes=[6, 2])\n",
    "sns.lineplot(x=\"datetime\", y=np.median(data[\"mean_task_latency\"]), c='#CC4F1B',data=data, ax=ax[0], dashes=True)\n",
    "ax[0].fill_between(\n",
    "    data[\"datetime\"],\n",
    "    np.median(data[\"mean_task_latency\"])-np.std(data[\"mean_task_latency\"]),\n",
    "    np.median(data[\"mean_task_latency\"])+np.std(data[\"mean_task_latency\"]),\n",
    "    alpha=0.2,\n",
    "    color=\"#CC4F1B\",\n",
    "    linestyle='dashdot', antialiased=True\n",
    "    )\n",
    "ax[0].set(title=\"Mean task latency\", ylabel='ms', xlabel='Time')\n",
    "ax2 = ax[0].twinx()\n",
    "\n",
    "color = 'tab:red'\n",
    "sns.lineplot(x=\"datetime\", y=\"total_agents\", c=color,data=data, ax=ax2, dashes=True)\n",
    "ax2.set_ylabel('MA', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "### Plot showing the mean battery saving for each agent compared to running locally\n",
    "sns.lineplot(x=\"datetime\", y=\"mean_battery_usage\", data=data, ax=ax[1])\n",
    "sns.lineplot(x=\"datetime\", y=np.median(data[\"mean_battery_usage\"]), data=data, ax=ax[1], dashes=True)\n",
    "ax[1].set(title=\"Mean saved power\", ylabel='mJ', xlabel='Time')\n",
    "\n",
    "### Plot showing algorithm convergence time\n",
    "sns.lineplot(x=\"datetime\", y=\"convergence_time\", data=data, ax=ax[2])\n",
    "sns.lineplot(x=\"datetime\", y=np.median(data[\"convergence_time\"]), data=data, ax=ax[2], dashes=True)\n",
    "ax[2].set(title=\"Algorithm convergence time\", ylabel='s', xlabel='Time')\n",
    "\n",
    "### Plot showing the correlation berween task latency and served mobile agents\n",
    "p1 = sns.relplot(x=\"mean_task_latency\", y=\"total_agents\", data=data, ax=ax[3])\n",
    "ax[3].set(title=\"Correlation between task latency and served mobile agents\")\n",
    "plt.close(p1.fig) # Workaround to eliminate double axis generated by relplot\n",
    "\n",
    "### Plot showing the correlation between task latency and battery consumption\n",
    "p2 = sns.relplot(x=\"mean_task_latency\", y=\"mean_battery_usage\", data=data, ax=ax[4])\n",
    "ax[4].set(title=\"Correlation between task latency and battery consumption\")\n",
    "plt.close(p2.fig) # Workaround to eliminate double axis generated by relplot\n",
    "\n",
    "fig.subplots_adjust(hspace=0.2)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Saving plots\n",
    "if hp.save_plots:\n",
    "    fig.savefig(\"../plots/g1_plots.pdf\")\n",
    "\n",
    "############# PLOTS: GROUP 2 #############\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(16, 12))\n",
    "# CDF for task latency\n",
    "powerlaw.plot_cdf(data=data[\"mean_task_latency\"], ax=ax[0])\n",
    "ax[0].set(title=\"CDF - Mean Task Latency\")\n",
    "\n",
    "# Relative load for each tier of edge nodes\n",
    "ax[1].stackplot(\n",
    "    data[\"datetime\"].values,\n",
    "    [data[\"t1-en-load\"].values, data[\"t2-en-load\"].values, data[\"t3-en-load\"].values ],\n",
    "    labels=['T1-EN','T2-EN','T3-EN']\n",
    "    )\n",
    "ax[1].legend(loc='upper left')\n",
    "ax[2].set(title=\"EN utilization (detail)\")\n",
    "ax[1].set_yscale(\"log\")\n",
    "\n",
    "fig.subplots_adjust(hspace=0.2)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Saving plots\n",
    "if hp.save_plots:\n",
    "    fig.savefig(\"../plots/g2_plots.pdf\")\n",
    "\n",
    "############# PLOTS: GROUP 3 #############\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Pie plot to show the percentage of EN usage for each tier\n",
    "ta = data[\"total_agents\"].sum()\n",
    "\n",
    "v1 = np.sum(data[\"t1-en-load\"]) * (TIER_1_EN * hp.T1_MAX_AGENTS) / ta\n",
    "v2 = np.sum(data[\"t2-en-load\"]) * (TIER_2_EN * hp.T2_MAX_AGENTS)/ ta\n",
    "v3 = np.sum(data[\"t3-en-load\"]) * (TIER_3_EN * hp.T3_MAX_AGENTS)/ ta\n",
    "v4 = data[\"cloud\"].sum() / ta\n",
    "v5 = data[\"local\"].sum() / ta\n",
    "\n",
    "ax[0].pie([v1, v2, v5, v3, v4], labels=['T1-EN','T2-EN','Local','T3-EN','Cloud'], autopct='%1.1f%%', shadow=True)\n",
    "ax[0].set(title=\"EN Utilization\")\n",
    "ax[0].axis('equal')\n",
    "\n",
    "# Pie plot to show the percentage of mobile agents saving battery\n",
    "pos = len(data[data.mean_battery_usage > 0].mean_battery_usage) / len(data)\n",
    "neg = len(data[data.mean_battery_usage < 0].mean_battery_usage) / len(data)\n",
    "\n",
    "ax[1].pie([ pos, neg], labels=['Less','More'], autopct='%1.1f%%', shadow=True)\n",
    "ax[1].set(title=\"Battery Utilization\")\n",
    "ax[1].axis('equal')\n",
    "\n",
    "fig.subplots_adjust(hspace=0.2)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Saving plots\n",
    "if hp.save_plots:\n",
    "    fig.savefig(\"../plots/g3_plots.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# HEATMAP PLOT #############\n",
    "\n",
    "# This doesn't work outside of Jupyter (apart from just saving the map in HTML)\n",
    "import folium\n",
    "from folium import plugins\n",
    "\n",
    "building_users_density_heatmap = folium.Map(\n",
    "    location=[48.150305,11.580054],\n",
    "    tiles='stamentoner',\n",
    "    zoom_start=12,\n",
    ")\n",
    "\n",
    "datas = []\n",
    "flattened = [item for sublist in coord_dataframe_list for item in sublist]\n",
    "for coord_list in flattened:\n",
    "    st = coord_list.assign(norm_total=(coord_list.total/coord_list.total.max()))\n",
    "    st.reset_index(inplace=True)\n",
    "    datas.append(st[['timestamp', 'latitude', 'longitude', 'total']].values.tolist())\n",
    "\n",
    "sl = []\n",
    "for idx, elem in enumerate(datas[0]):\n",
    "    temp = []\n",
    "    for i in range(len(datas)):\n",
    "        try:\n",
    "            temp.append([datas[i][idx][1], datas[i][idx][2], datas[i][idx][3]])\n",
    "        except IndexError:\n",
    "            pass\n",
    "    sl.append(temp)\n",
    "\n",
    "hmt = plugins.HeatMapWithTime(sl,auto_play=True,use_local_extrema=True, max_opacity=0.8,index=flattened[0].reset_index().timestamp.tolist())\n",
    "hmt.add_to(building_users_density_heatmap)\n",
    "\n",
    "# building_users_density_heatmap\n",
    "building_users_density_heatmap.save('../plots/building_users_density_heatmap.html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit3915ded6a3b3497fbcf35314c66b2b6c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}